{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from multiprocessing import Queue, Process\n",
    "import time\n",
    "import multiprocessing\n",
    "from multiprocessing import cpu_count\n",
    "from numpy import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy\n",
    "from threading import Thread\n",
    "# import random  \n",
    "from random import sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loadTrainDataSet():\n",
    "    '''\n",
    "    加载训练数据\n",
    "    '''\n",
    "    train_data1 = pd.read_csv('./data/train1.csv',header=None)\n",
    "    train_data2 = pd.read_csv('./data/train2.csv',header=None)\n",
    "    train_data3 = pd.read_csv('./data/train3.csv',header=None)\n",
    "    train_data4 = pd.read_csv('./data/train4.csv',header=None)\n",
    "    train_data5 = pd.read_csv('./data/train5.csv',header=None)\n",
    "    \n",
    "    label1 = pd.read_csv('./data/label1.csv',header=None)\n",
    "    label2 = pd.read_csv('./data/label2.csv',header=None)\n",
    "    label3 = pd.read_csv('./data/label3.csv',header=None)\n",
    "    label4 = pd.read_csv('./data/label4.csv',header=None)\n",
    "    label5 = pd.read_csv('./data/label5.csv',header=None)\n",
    "    \n",
    "    train = pd.concat([train_data1, train_data2, train_data3, train_data4, train_data5], sort=False)\n",
    "    label = pd.concat([label1, label2, label3, label4, label5], sort=False)\n",
    "    \n",
    "    train = np.array(train)\n",
    "    label = np.array(label)\n",
    "    \n",
    "    train = np.c_[train, label]\n",
    "    return np.array(train)\n",
    "\n",
    "\n",
    "def loadTestDataSet():\n",
    "    '''\n",
    "    加载测试数据\n",
    "    '''\n",
    "    test_data1 = pd.read_csv('./data/test1.csv',header=None)\n",
    "    test_data2 = pd.read_csv('./data/test2.csv',header=None)\n",
    "    test_data3 = pd.read_csv('./data/test3.csv',header=None)\n",
    "    test_data4 = pd.read_csv('./data/test4.csv',header=None)\n",
    "    test_data5 = pd.read_csv('./data/test5.csv',header=None)\n",
    "    test_data6 = pd.read_csv('./data/test6.csv',header=None)\n",
    "    test_data = pd.concat([test_data1, test_data2, test_data3, test_data4, test_data5, test_data6], sort=False)\n",
    "    test_data = np.array(test_data)\n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一棵树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionTree:\n",
    "    def __init__(self, min_increase_gain = 1, min_samples_split = 100):\n",
    "        '''\n",
    "        min_increase_gain: 一个节点分裂以后误差的最小减少值，当值小于这个值的时候停止分裂\n",
    "        min_samples_split: 每个叶子的最小样本数\n",
    "        '''\n",
    "        self.min_increase_gain = min_increase_gain\n",
    "        self.min_samples_split = min_samples_split\n",
    "    \n",
    "    def binSplitDataSet(self, dataSet, feature, value):\n",
    "        ''' \n",
    "        划分数据集,\n",
    "        这里进行了cache的优化，使用方案1的时候跑得太慢了，每次都要遍历全部的特征\n",
    "        改变以后，由于传进来的dataSet是按照feature排序的，所以当一个大于当前的value的时候，我们就可以将数据集划分开来了\n",
    "        '''\n",
    "        '''\n",
    "        方案1\n",
    "        dataSet00 = []\n",
    "        dataSet11 = []\n",
    "        for i in range(len(dataSet)):\n",
    "            if dataSet[i][feature] > value:\n",
    "                dataSet00.append(dataSet[i])\n",
    "            else:\n",
    "                dataSet11.append(dataSet[i])\n",
    "             \n",
    "        return np.array(dataSet00), np.array(dataSet11)\n",
    "        '''\n",
    "        # 方案2\n",
    "        index = -1\n",
    "        dataSet0 = []\n",
    "        dataSet1 = []\n",
    "        for i in range(len(dataSet)):\n",
    "            if dataSet[i][feature] > value:\n",
    "                index = i\n",
    "                break\n",
    "        \n",
    "        if index == 0:\n",
    "            return dataSet, np.array(dataSet0)\n",
    "        elif index == -1:\n",
    "            return np.array(dataSet0), dataSet\n",
    "        else:\n",
    "            dataSet1 = dataSet[0:index]\n",
    "            dataSet0 = dataSet[index:]\n",
    "            return np.array(dataSet0),np.array(dataSet1)\n",
    "    \n",
    "    def leafValue(self, dataSet):\n",
    "        '''\n",
    "        求叶子的均值，作为最后预测的结果\n",
    "        '''\n",
    "        return mean(dataSet[:,-1])\n",
    "    \n",
    "    \n",
    "    def leafVar(self, dataSet):\n",
    "        '''\n",
    "        求方差，用于选取最佳分割点\n",
    "        '''\n",
    "        return var(dataSet[:,-1]) * shape(dataSet)[0]\n",
    "\n",
    "        \n",
    "    def chooseBestSplit(self, dataSet):\n",
    "        '''\n",
    "        选取最佳分割点，在对数据进行分割之前，先对特征进行排序，\n",
    "        以减少cache与内存的换页，可以有效减少训练时间\n",
    "        \n",
    "        '''\n",
    "        # 如果叶子的所有值相等，不需要继续划分\n",
    "        if len(set(dataSet[:,-1].T.tolist())) == 1:\n",
    "            return None, self.leafValue(dataSet)\n",
    "        m, n = shape(dataSet)\n",
    "        # 计算父节点方差\n",
    "        parentVar = self.leafVar(dataSet)\n",
    "        bestVar = inf\n",
    "        bestIndex = 0\n",
    "        bestValue = 0\n",
    "        # 随机选取分割特征\n",
    "        # 设置随机种子，在多进程的情况下，需要设置，否则生成的随机数不是严格意义上的随机数\n",
    "        # 随机选择特征的1/3来进行分割\n",
    "        random_features = sample(range(0, n - 1),int((n-1)/3))\n",
    "        \n",
    "        for featIndex in random_features:\n",
    "            # 对特征进行排序，减少换页\n",
    "            temp = [x[featIndex] for x in dataSet]\n",
    "            index = np.argsort(temp ,axis=0)\n",
    "            dataSet = dataSet[index]\n",
    "            temp.sort()\n",
    "            temp = list(set(temp))\n",
    "            t = []\n",
    "            for i in range(len(temp)):\n",
    "                if i == 0:\n",
    "                    tag = temp[i]\n",
    "                    t.append(temp[i])\n",
    "                else:\n",
    "                    if temp[i] - tag > 1:\n",
    "                        t.append(temp[i])\n",
    "                        tag = temp[i]\n",
    "            temp = t\n",
    "            for splitVal in temp:\n",
    "                dataSet0, dataSet1 = self.binSplitDataSet(dataSet, featIndex, splitVal)\n",
    "                # 当分割后的叶子小于叶子最少样本数时，不需要分割\n",
    "                if (shape(dataSet0)[0] < self.min_samples_split) or (shape(dataSet1)[0] < self.min_samples_split): \n",
    "                    continue\n",
    "                # 分割后的方差\n",
    "                newVar = len(dataSet0)/len(dataSet)*self.leafVar(dataSet0) + len(dataSet1)/len(dataSet)*self.leafVar(dataSet1)\n",
    "                # 分割后的方差与分割前的进行比较，去较好值\n",
    "                if newVar < bestVar: \n",
    "                    bestIndex = featIndex\n",
    "                    bestValue = splitVal\n",
    "                    bestVar = newVar\n",
    "        # 如果增益过小，不需要分割\n",
    "        if (parentVar - bestVar) < self.min_increase_gain: \n",
    "            return None, self.leafValue(dataSet)\n",
    "        \n",
    "        temp = [x[bestIndex] for x in dataSet]\n",
    "        # temp = dataSet[:,featIndex]\n",
    "        index = np.argsort(temp ,axis=0)\n",
    "        dataSet = dataSet[index]\n",
    "        dataSet0, dataSet1 = self.binSplitDataSet(dataSet, bestIndex, bestValue)\n",
    "        if (shape(dataSet0)[0] < self.min_samples_split) or (shape(dataSet1)[0] < self.min_samples_split):\n",
    "            return None, self.leafValue(dataSet)\n",
    "        \n",
    "        return bestIndex, bestValue\n",
    "    \n",
    "    def createTree(self, dataSet, deep = 20):\n",
    "        '''\n",
    "        综合上面过程，建一棵完整的树\n",
    "        递归实现\n",
    "        '''\n",
    "        deep -= 1\n",
    "        if deep == 0:\n",
    "            return self.leafValue(dataSet)\n",
    "        feat, val = self.chooseBestSplit(dataSet)\n",
    "        if feat == None: \n",
    "            return val\n",
    "        retTree = {}\n",
    "        retTree['featureIndex'] = feat\n",
    "        retTree['spiltValue'] = val\n",
    "        temp = [x[feat] for x in dataSet]\n",
    "        index = np.argsort(temp ,axis=0)\n",
    "        dataSet = dataSet[index]\n",
    "        lSet, rSet = self.binSplitDataSet(dataSet, feat, val)\n",
    "        retTree['left'] = self.createTree(lSet, deep)\n",
    "        retTree['right'] = self.createTree(rSet, deep)\n",
    "        return retTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestRegressor:\n",
    "    def __init__(self, n_estimators = 2, max_depth = 20, sample_ratio = 0.1, min_sample_spilt = 100, process_num = 8, min_increase_gain = 1):\n",
    "        '''\n",
    "        n_estimators：树的个数\n",
    "        max_depth：树的最大深度 \n",
    "        sample_ratio：取样时候的比例\n",
    "        min_sample_spilt：叶子最小样本数\n",
    "        process_num：使用的进程数量\n",
    "        '''\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.forests = []\n",
    "        self.sample_ratio = sample_ratio\n",
    "        self.min_sample_spilt = min_sample_spilt\n",
    "        self.process_num = process_num\n",
    "        self.min_increase_gain = min_increase_gain\n",
    "        \n",
    "    def predict_one_tree(self, tree, data):\n",
    "        return predict(data)\n",
    "    \n",
    "    def fit(self, dataSet):\n",
    "        # 多进程操作\n",
    "        pool = multiprocessing.Pool(processes = self.process_num)\n",
    "        start = time.time()\n",
    "        result = []\n",
    "        for i in range(self.n_estimators):\n",
    "            result.append(pool.apply_async(self.build_tree_mulprocess, args=(i, dataSet,)))\n",
    "        \n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        end = time.time()\n",
    "        print('time:', (end - start))\n",
    "        for r in result:\n",
    "            self.forests.append(r.get())\n",
    "\n",
    "    def build_tree_mulprocess(self, i, dataSet):\n",
    "        \"\"\"\n",
    "        用于建树的进程\n",
    "        \"\"\"\n",
    "        print('Building tree ', i, ' ...')\n",
    "        sample_dataSet = self.get_sample_dataSet(dataSet, i)\n",
    "        t = RegressionTree(min_increase_gain=self.min_increase_gain, min_samples_split=self.min_sample_spilt)\n",
    "        tree = t.createTree(sample_dataSet, self.max_depth)\n",
    "        print('Build tree ', i, ' end')\n",
    "        return tree\n",
    "\n",
    "    def get_sample_dataSet(self, dataSet, i):\n",
    "        '''\n",
    "        有放回选取数据集，\n",
    "        smple_ratio是选取的数据集占原样本的比例\n",
    "        '''\n",
    "        print('Getting data for tree ', i)\n",
    "        sample_size = round(len(dataSet) * self.sample_ratio)\n",
    "        sample_dataSet = []\n",
    "        random_indexs = []\n",
    "        while len(random_indexs) < sample_size:\n",
    "            random_indexs.append(random.randint(0, len(dataSet)-1))\n",
    "        \n",
    "        # 排序再取，避免过多分页\n",
    "        random_indexs.sort()\n",
    "        for j in random_indexs:\n",
    "            sample_dataSet.append(np.array(dataSet[j]).reshape(14))\n",
    "        print('Get data for tree ', i, ' end')\n",
    "        return np.array(sample_dataSet)\n",
    "    \n",
    "    def getForest(self):\n",
    "        return self.forests\n",
    "    \n",
    "    def predict(self, data):\n",
    "        '''\n",
    "        预测森林的效果\n",
    "        '''\n",
    "        result = []\n",
    "        for j in range(len(data)):\n",
    "            if j%10000 == 0:\n",
    "                print('[{}] of [{}]'.format(j, len(data)))\n",
    "            s = 0\n",
    "            for i in range(len(self.forests)):\n",
    "                temp = self.forests[i]\n",
    "                while 1:\n",
    "                    if type(temp) == np.float64:\n",
    "                        s += temp\n",
    "                        break\n",
    "                    index = temp['featureIndex']\n",
    "                    d = data[j][index]\n",
    "                    if d > temp['spiltValue']:\n",
    "                        temp = temp['left']\n",
    "                    else:\n",
    "                        temp = temp['right']\n",
    "            result.append(s/len(self.forests))\n",
    "        return np.array(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建随机森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = loadTrainDataSet()\n",
    "test_data = loadTestDataSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = RandomForestRegressor(n_estimators = 100, max_depth = 10, sample_ratio=0.01, min_sample_spilt = 1000, process_num = 8)\n",
    "r.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.getForest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = r.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Predicted':result})\n",
    "df.index += 1\n",
    "df.to_csv('./data/my_sub.csv', index = True, index_label = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.07026454, -0.1277874 , -0.14017351, -0.08749159,  0.01166582,\n",
       "       -0.01162952, -0.00843141, -0.03494192, -0.07022627, -0.1134285 ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
